---
title: "ST211mini project"
author: "Group4"
output: html
self-contained: true
editor:
    render-on-save: true
    preview: true
---

## Set up
```{r message=FALSE, warning=FALSE}
# set up
library(dplyr)       
library(tidyr)      
library(readr)      
library(lubridate)
library(arm)
library(tidyselect)
library(ggplot2)
```

```{r}
# Data Loading
data<-read.csv("data/RWNS_final.csv", header=TRUE,stringsAsFactors=TRUE)
```

# Have a look at the data
```{r}
head(data)
summary(data)
```

## `fiveac` vs k4score
```{r warning=FALSE, message=FALSE}
fiveac_g<-ggplot(data=data, aes(x=fiveac,y=ks4score)) +
  geom_boxplot() +
  labs(title="Boxplot of 5 A*-C Subjects vs GCSE Scores",
         x="5 A*-C Subjects",
         y="GCSE Scores")
fiveac_g
```
It's obvious that both median and IQR is higher for students who have 5 or more A*-C subjects. This is quite intuitive as students who have more GCSE subjects that are grade from A star to C tend to have higher GCSE scores. Thus, we will include this variable to our final model as well.

## `fiveem` vs k4score
The inclusion of this variable is quite questionable, because it's overlapped with the `fiveac` variable, while `fiveac` is a subset of `fiveem` which includes English and Maths. However, to make our final model more accurate, we created simple linear regressions for both variables and tested their R-squraed values to see which one is more significant.

```{r warning=FALSE, message=FALSE}
fiveac_lm <- lm(ks4score ~ fiveac, data = data)
display(fiveac_lm)
```
```{r}
fiveem_lm <- lm(ks4score ~ fiveem, data = data)
display(fiveem_lm)
```
By displaying the results of both regression, the R-squared value of the `fiveac` variable is 0.57, while the R-squared value of the `fiveem` variable is 0.46. This indicates that the `fiveac` variable is slightly more significant than the `fiveem` variable. It's quite reasonable because it's easier to get a higher grade on basic subjects like English and Maths compared to other subjects. Thus, students who have more A*-C subjects excluding basic subjects tend to have higher GCSE scores. Therefore, we will include the `fiveac` variable to our final model, and exclude the `fiveem` variable.


## `IDACI_n` vs k4score

By viewing the dataset, we can see that there are one columns that contain numerical variables which is **"IDACI_n"**. Here, we chose to first use `scatter plots` to see the relationship of this variable with the target variable. This is because with numerical data, the scatter plot can show `a best fitting line` which indicates the trending of the data.

```{r warning=FALSE, message=FALSE}
IDACI_g<-ggplot(data, aes(x = IDACI_n, y = ks4score)) + 
  geom_point(alpha=0.2, size=3, color="lightblue", stroke=1) + 
  geom_smooth(method = "lm",  
              se = FALSE) + 
  theme_minimal() + 
  labs(title = "Scatter Plot of Deprivation vs GCSE Scores with Fitted Line",
       x = "Index of Deprivation",
       y = "GCSE Scores")

IDACI_g
```
From the plot, we can see that there is a slightly downward trend in the fitted line, which indicates that the higher the deprivation index, the lower the GCSE scores. It's quite intuitive that students with more deprived background tend to receive less-qualified education, and thus resulting to lower GCSE scores.

However, it's not reasonable to conclude that the deprivation index is a significant factor that affects the GCSE scores from the plot. We need to further investigate the relationship between the deprivation index and the GCSE scores by using a **simple linear regression model**.

```{r}
# Simple linear regression model
IDACI_lm <- lm(ks4score ~ IDACI_n, data = data)
summary(IDACI_lm)
```
From the summary of the simple linear regression model, we can see that the p-value of the coefficient of the deprivation index is less than 0.05, which indicates that this negative relationship is statistically significant. However, at the same time, the R-squared value is only 0.05, showing that the deprivation index only explains 5% of the variation in GCSE scores. Therefore, we can conclude that the deprivation index is a significant factor that affects the GCSE scores, but it's not the only factor.

## `house` vs k4score
```{r warning=FALSE, message=FALSE}
house_g<-ggplot(data=data, aes(x=house,y=ks4score)) +
  geom_boxplot() +
  labs(title="Boxplot of Housing Status vs GCSE Scores",
         x="Housing Status",
         y="GCSE Scores")
house_g
```
From the boxplot, we can see that the difference amongst the three housing statuses is not that significant except for a slightly higher median and range for students with owned houses. Besides, the `other/DK/Ref` value is quite tricky to interpret.

What's more, we believe that the housing status has a relaship with deprivation index. Thus, we created another boxplot for housing status versus deprivation index.
```{r warning=FALSE, message=FALSE}
house_IDACI_g<-ggplot(data=data, aes(x=house,y=IDACI_n)) +
  geom_boxplot() +
  labs(title="Boxplot of Housing Status vs Deprivation Index",
         x="Housing Status",
         y="Deprivation Index")
house_IDACI_g
```
Unsurprisingly, the boxplot shows that students who live in rented houses tend to have higher deprivation index, which means that they are more likely to be from a deprived background. To some extent, the housing status information is overlapped with deprivation index, and the given the high significance of the index, we will exclude `house` variable from our final model.

## `gender` vs k4score
```{r}
## gender: no clear relationship between gender and ks4score
ggplot(data, aes(x=gender,y=ks4score, color=gender)) + geom_boxplot() + labs(title = 'Boxplot between Gender and Ks4score')
```
From the boxplot, we can see that there is no clear relationship beteween gender and ks4score, so we will remove the gender variable from our predicition model. 

## `singlepar` vs k4score
```{r}
ggplot(data, aes(x=singlepar,y=ks4score, color=singlepar)) + geom_boxplot() + labs(title = 'Boxplot between Students with or without Single Parent and Ks4score')
```
Students without single parent have a higher overall ks4score than students with single parent. 

## `attitude` vs k4score
```{r}
ggplot(data, aes(x=reorder(attitude, ks4score, median),y=ks4score, color=attitude)) + geom_boxplot() + labs(title = 'Boxplot between Attitude and Ks4score')
```
Students with very_high attitude tend to have higher median ks4score compared to students with very_low attitude.  

```{r}
# Simple linear regression model for attitude
attitude_lm <- lm(ks4score ~ attitude, data = data)
summary(attitude_lm)
```
The regression model for attitude suggests that 5% of the variability in GCSE score can be explained by students' attitude. Although the attitude factor is statistically significantly, there are many other variables that are not accounted for that influence academic performance. 

## `FSMband` vs k4score
```{r}
ggplot(data, aes(x=FSMband,y=ks4score, color=FSMband)) + geom_boxplot()
```
Different percent of students in the school entitled to FSM have varying ks4score. 

## `hiquam` vs k4score
```{r}
ggplot(data, aes(x=reorder(hiquamum, ks4score, median),y=ks4score, color=hiquamum)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
Students with different level of mothers highest educational qualification have different ks4score, where degree_or_equivalent have the highest median ks4score and no_qualification has the lowest ks4score. 

## `k3` vs k4score
```{r}
# select subset of data for k3 variable
data_k3 <- data[c("ks4score","k3en", "k3ma", "k3sc")]
# tidy up the data for ggplot
tidydata_k3 <- data_k3 %>%
  pivot_longer(cols = -"ks4score", names_to="k3", values_to="level")
tidydata_k3
ggplot(tidydata_k3, aes(x=k3,y=ks4score, color=k3)) + geom_boxplot()
```
The boxplot of k3en, k3ma, and k3ec shows that there is no clear relationship between ks3 subject scores and ks4scores. Since the three variables are highly correlated with each other, they can be combined together when running the regression model. 

```{r}
# Simple linear regression model for k3
k3_lm <- lm(ks4score ~ k3en+k3ma+k3sc, data = data)
summary(k3_lm)
```
By running the regression model for k3 and ks4score, we can see that k3 and ks4score has a positive relationship, where the p-value < 2e-16 confirms that the relationship is statistically significant. The R-squared value of 0.5813 further implies that 58% of the variability in GCSE score can be explained by k3, indicating a strong model fit. However, the wide range of residuals suggests that while the model has predictive power, there are likely other factors not captured by this model that influence ks4score.

## `exclude` vs k4score
```{r}
ggplot(data, aes(x=exclude,y=ks4score, color=exclude)) + geom_boxplot() + labs(title = 'Boxplot between exclude and Ks4score')
```
Students with one ore more exclusions from school age 11-14 has a significantly lower ks4score compared to students without exclusions. 

## `truancy` vs k4score
```{r}
ggplot(data, aes(x=truancy,y=ks4score, color=truancy)) + geom_boxplot() + labs(title = 'Boxplot between truancy and Ks4score')
```
Similar to exclusion, students who is traunt in the last 12 months has a lower ks4score compared to students without truancy. 

## `absent` vs k4score
```{r}
ggplot(data, aes(x=absent,y=ks4score, color=absent)) + geom_boxplot() + labs(title = 'Boxplot between absent and Ks4score')
```
Students who is absent for more than one month during Y9 has a lower ks4score than students who are not absent. 

Looking at the three boxplots above, we can see that students who are absent, truant, or excluded during school time generally performed worse on GCSE exams. Hence, the three predictors can be merged together when running regression models.

```{r}
# Simple linear regression model for absent, exclude, and truancy
absent_lm <- lm(ks4score ~ absent+exclude+truancy, data = data)
summary(absent_lm)
```
The linear model shows that all predictors other than absentYes and excludeNo are statistically significant. However, these behavioral factors (absent, exclude, truancy) explain only 12% variability of the GCSE score. 

## `SECshort` vs k4score
```{r}
ggplot(data, aes(x=reorder(SECshort, ks4score, median),y=ks4score, color=SECshort)) + geom_boxplot() + labs(title = 'Boxplot between SECshort and Ks4score') + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
The boxplot for SECshort shows that the median ks4score for managerial is the highest, followed by intermediate, missing, and routine, semi-routine and unemployed. 

## `parasp` and `pupasp` vs k4score
```{r}
ggplot(data, aes(x=parasp,y=ks4score, fill=pupasp)) + geom_boxplot() + labs(title = 'Boxplot between parasp, pupasp, and Ks4score')
```
The boxplot shows that students who want to continue in FTE after age 16 has a significantly higher ks4score in all three cases (no, yes, missing) for whether parent wishes YP to continue in FTE post 16.

```{r}
# Simple linear regression model for parasp and pupasp
pasp_lm <- lm(ks4score ~ parasp*pupasp, data = data)
summary(pasp_lm)
```
From the model above, we can see that pupaspYes shows a positive relationship with GCSE score, and the model explains around 12 percent of the variation in GCSE score. 
